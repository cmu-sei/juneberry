#! /usr/bin/env bash

# =================================================================================================
# WARNING: These containers and scripts create containers with NO SECURITY PRACTICES, such as
# separate user accounts, unprivileged users, etc.**
#
# USE AT YOUR OWN RISK
# =================================================================================================

# This is a sample startup script for the Juneberry container.  Please feel free to copy
# and modify as needed.

# === DOCKER BUILD ===
# This assumes the Juneberry container was built with a tag of "juneberry/<type>:dev", such as:
# docker build -f cudadev.Dockerfile -t juneberry/cudadev:dev .
# or
# docker build -f cpudev.Dockerfile -t juneberry/cpudev:dev .

# === PROXIES ===
# To set proxies during the build, specify them via build args. For example:
# docker build --build-arg HTTP_PROXY=${HTTP_PROXY} ... -f juneberry.Dockerfile -t juneberry/cudadev:dev .

# === PROJECT LAYOUT ===
# When starting this container, a variety of directories for organizing the current code, data,
# tensorboard output, caches, and workspaces (optional) will get mounted (not copied) into the container.
# This script assumes a single "project" directory (passed in as the one argument), with the mounted directories
# organized as subdirectories according to the following layout:
# <project>/
#   juneberry <- This is the Juneberry repo that was pulled
#   dataroot <- This is where the source data is located, i.e. the Juneberry "dataroot".
#   tensorboard <- This is where tensorboard outputs will be stored.
#   cache <- This where the model downloads are cached.
#   workspace <- This is an optional external workspace directory, see docker/README.md for details

# Set our default arguments
CONTAINER="juneberry/cudadev:dev"
#CONTAINER="juneberry/cpudev:dev"

# This value determines which GPUs the container will be aware of.  "all" is default.
# Set to "" for none. Specific GPUs can be set by listing the devices as one would
# with CUDA_VISIBLE_DEVICES.
GPUS="--gpus all"
# GPUS=""
# GPUS="--gpus \"device=2,3\""
# GPUS="--gpus \"device=${CUDA_VISIBLE_DEVICES}\""

function show_help() {
  echo "Usage: [-w <workspace>] [-c <container>] [-g <gpus>] <project>"
  echo "Optional arguments:"
  echo "    -w <workspace> - Optional: The path to a custom workspace."
  echo "    -c <container> - Optional: Name of the container. The default is ${CONTAINER}."
  echo "    -g <gpus>      - Optional: The number of gpus.  The default is ${GPUS}."
  echo "    -h <gpus>      - Show this message and exit."
}

# === Process the command line arguments.

DOHELP=0
while getopts w:c:g:h option; do
  case $option in
  w) WS=$OPTARG ;;
  c) CONTAINER=$OPTARG ;;
  g) GPUS=$OPTARG ;;
  h) DOHELP=1 ;;
  esac
done
shift $((OPTIND - 1))

# Show usage and exit if we don't get at least one command line argument or they ask for help
if ([ ${DOHELP} -eq 1 ] || [ $# -ne 1 ]); then
  show_help
  exit 1
fi

# PROJ is the remaining argument
PROJ=${1}

# === Generate all the derivative settings
echo "Using project '${PROJ}'..."

# Docker run specific commmands

# The -rm means the container is destroyed upon exit.  This is okay because the useful data persists
# in the mounted locations.
BASE="-it --rm --network=host --ipc=host"
ENVS="--env HTTP_PROXY --env http_proxy --env HTTPS_PROXY --env https_proxy --env NO_PROXY --env no_proxy"
ENVS_USER="-e USER_NAME=${USER} -e USER_ID=$(id -u ${USER}) -e USER_GID=$(id -g ${USER})"
NAME="--name ${USER}"

# Directory layout

# These are all the mount points into the container so the code, data, and outputs persist across container starts.
# Feel free to change the paths to the left of the colon as needed. These sub-directories are not required to all be in
# the same project directory.
JB="-v ${PROJ}/juneberry:/juneberry"

# If the user didn't pass a workspace argument, make Juneberry
# the working directory. Otherwise, setup the workspace and
# if that's successful, make the workspace directory the working directory.
# NOTE: The '//' in the worksapce is for Git Bash support
if [ -z ${WS} ]; then
  echo "Using default workspace..."
  JB="${JB} -w //juneberry"
else
  echo "Using workspace ${WS}..."
  ${PROJ}/juneberry/scripts/setup_workspace.py -p ${PROJ} -w ${WS}
  if [ $? -eq 0 ]; then
    WS="-v ${WS}:/workspace -w //workspace"
  fi
fi

DATA="-v ${PROJ}/dataroot:/dataroot:ro"
TB="-v ${PROJ}/tensorboard:/tensorboard"
HUB_CACHE="-v ${PROJ}/cache/hub:/root/.cache/torch/hub"
TORCH_CACHE="-v ${PROJ}/cache/torch:/root/.torch"

# Assemble the command, show it, and run it.
CMD="docker run ${BASE} ${ENVS} ${ENVS_USER} ${GPUS} ${JB} ${WS} ${DATA} ${TB} ${HUB_CACHE} ${TORCH_CACHE} ${NAME} ${CONTAINER} bash"
echo "${CMD}"
${CMD}
