Report Configuration Specification
==========


# Introduction
This document describes the schema for the JSON formatted Juneberry Report configuration file. This 
schema has a unique behavior when compared to other Juneberry configuration files, in that it may 
exist within its own configuration file OR be inserted into other schemas, such as model configs 
or experiment configs.

# Schema - Basic
The following schema applies to standalone ReportConfigs, or any "reports" stanzas that have been 
inserted into model configs or experiment configs.
```
{
    "reports": [
        {
            "description": <Human readable description of this report>,
            "fqcn": <fully qualified name of a class that extends the juneberry.reporting.report base class>,
            "kwargs": { <OPTIONAL kwargs to be passed (expanded) to __init__ on construction> }
        }
    ]
}
```

## Report Specific Schemas

Juneberry includes a few built-in Report classes. This section describes the schemas for each 
of the available Report types.

### Schema - ROC Report
The ROC Report type uses model evaluation output data to generate a plot with one or more RoC curves.
```
{
    "description": <Human readable description of this report>,
    "fqcn": <A string, must be equal to "juneberry.reporting.roc.ROCPlot">
    "kwargs": {
        "output_filename": <A string indicating the desired location for the output image>,
        "plot_title": <A string indicating the desired title for the Figure>,
        "legend_scaling": <A float indicating the scale factor to apply to the legend>,
        "legend_font_size": <An integer that controls the font size in the legend>,
        "line_width": <An integer that controls the line width in the figure>,
        "curve_sources": {A dictionary of key:value pairs, where each key represents a 
                          "predictions.json" file produced by a model evaluation, and the 
                          value represents which classes to generate ROC curves for from that 
                          predictions data.}
    }
}
```

### Schema - PR Report
The PR Report type will generate Precision-Recall-Confidence plots.
```
{
    "description": <Human readable description of this report>,
    "fqcn": <A string, must be equal to "juneberry.reporting.pr.PRCurve">
    "kwargs": {
        "output_dir": <A string indicating the desired output directory for storing the images 
                       generated by this report>,
        "iou": <A float indicating the iou threshold to use when calculating the curves in this report>,
        "tp_threshold": <A float indicating the true-positive threshold to use when calculating the 
                         curves in this report>,
        "stats_fqcn": <A string indicating which class to use in the Juneberry MetricsManager>,
        "curve_sources": <A dictionary of key:value pairs, where each key corresponds to a trained model 
                          and the value represents a dataset that was used to evaluate that model. A PR 
                          curve will be added to the figures for each model:dataset pair.>
    }
}
```

### Schema - Summary Report
The Summary Report type will generate a simple markdown report (and optional CSV) that summarizes 
model training and eval results, and displays or links to any training graphs and plots that were 
produced.
```
{
    "description": <Human readable description of this report>,
    "fqcn": <A string, must be equal to "juneberry.reporting.summary.Summary">
    "kwargs": {
        "md_filename": <A string indicating the desired output filename for the Summary markdown file>,
        "csv_filename": <A string indicating the desired output filename for the Summary CSV file>,
        "metrics_files": <A list of strings, where each string represents a Juneberry metrics.json 
                          file which the Report should pull Summary information from>,
        "plot_files": <A list of strings, where each string represents an image file to include in 
                       the Summary report>
    }
}
```

# Plugin Structure

The Juneberry Report schema follows the same basic pattern as other Juneberry Plugins. A class is 
specified by its Fully Qualified Class Name (FQCN) and a dictionary of keyword arguments can be 
passed in during construction. A Report Class is typically written with an init method and a 
"create_report" method.

The following code depicts a simple example of a Report Class with two arguments in the init method 
and a "create_report" method to produce the report:

```python
from juneberry.reporting.report import Report

class ExampleReport(Report):
    def __init__(self, report_output_dir: str, model_name: str, accuracy: float):
        super().__init__(output_str=report_output_dir)
        self.model_name = model_name
        self.accuracy = accuracy
        
    def create_report(self) -> None:
        print(f"Model name: {self.model_name}\n  Accuracy: {self.accuracy}")
```

The `kwargs` stanza when using this Report should have `model_name` and `accuracy` properties:

```json
{
    "kwargs": {
        "report_output_dir": "/juneberry/report_output_dir",
        "model_name": "ResNet",
        "accuracy": 0.5
    }
}
```

If the code for the Example report was stored in a file named `juneberry/reporting/example.py`, then the 
full report stanza would look something like this:

```json
{
    "description": "Report stanza illustrating how to use ExampleReport",
    "fqcn": "juneberry.reporting.example.ExampleReport",
    "kwargs": {
        "report_output_dir": "/juneberry/report_output_dir",
        "model_name": "ResNet",
        "accuracy": 0.5
    }
}
```

The previous stanza could then be inserted into the "reports" list of a report config file, a 
model config file, or an experiment config file.

# Schema Adjustments in an Experiment Config
**TODO**
When a "reports" stanza is inserted into an experiment config, the Reports schema includes a few 
additional fields which are exclusively used by Juneberry experiments. 

# Schema Details
This section provides more information about each of the fields in the basic Report schema.

## reports
A list of reports to produce, where each Report is represented by a single Report plugin as 
described in the [Plugin Structure](#Plugin Structure) section.

### description
A human-readable description of the report.

### fqcn
The fully qualified class name (fqcn) of the Report to build, e.g. 
"**juneberry.reporting.summary.Summary**".

### kwargs
A dictionary containing all the arguments to pass into the `__init__` method of the 
Report class indicated in the 'fqcn' field.

## Schema Details - ROC Report
This section provides more information about each of the fields in the schema for a 
ROC Report stanza.

### description
A human-readable description of the report.

### fqcn
The fully qualified class name (fqcn) of the Report to build, which for a Juneberry 
ROC Report should be equal to "**juneberry.reporting.roc.ROCPlot**".

### kwargs
A dictionary containing all the arguments to pass into the `__init__` method of 
**juneberry.reporting.roc.ROCPlot**.

#### output_filename
A string indicating the desired name for the output file. The output file is a figure 
contain ROC curves, so typically this field will be a PNG file. When this field is not 
provided, the ROC image will be placed in the current working directory using the 
filename "ROC_curves.png". When this field is set to a directory, the ROC image will 
be placed inside that directory using the filename "ROC_curves.png". 

#### plot_title
This string will be used for the title of the Figure in the ROC plot. When this field 
is not provided, the Report uses "ROC Curve(s)" for the figure title.

#### legend_scaling
A float that can be used to adjust the scale factor for the legend. When this field 
is not provided, the Report uses 1.0 as the default value.

#### legend_font_size
This integer is used to control the fontsize of the text in the legend. When this field 
is not provided, the Report uses 10 as the default value.

#### line_width
This integer controls the width of ROC curve lines in the figure. When this field is 
not provided, the Report uses 2 as the default value.

#### curve_sources
This dictionary contains key:value pairs that indicate which evaluation data and classes 
should be used to generate ROC curves for the figure. 

A key should be a string indicating 
a Juneberry Evaluation Output file (see the [Evaluation Output Specification](eval_output_specification.md)). 

The corresponding value should be a string of classes in the evaluation data to produce ROC 
curves for. The following examples illustrate various ways to construct the class string:
 - 'all' - Plots an ROC curve for each class in the evaluation data.
 - '0,1,2' - Plots three different ROC curves, one for class 0, one for class 1, and one for class 2.
 - '0,dog,1' - Plots three different ROC curves, one for class 0, one for the 'dog' class (the Report 
will look up the class string and convert to the correct integer class), and one for class 2.
 - '0,1+2,3' - Plots three different ROC curves, one for class 0, one for class 1 and 2 data combined 
into a single curve, and one for class 3.
 - 'cat, 3+dog, 4' - Various combinations of the previous techniques are supported. The Report will 
simply convert any strings to the corresponding integers and perform class combinations as requested.

Therefore, a correctly constructed 'curve_sources' property would look something like this:
```json
{
    "curve_sources": {
        "models/example_model/eval/example_dataset/predictions.json": "0,1,2",
        "models/example_model2/eval/example_dataset/predictions.json": "0,dog+cat,2"
    }
}
```

This set of curve sources would produce a Figure containing 6 ROC curves from 2 different models which 
were evaluated using the same evaluation dataset. Each model provides the data for 3 curves. The 
second curve from example_model2 will be a combined curve for the dog and cat classes.

## Schema Details - PR Report
This section provides more information about each of the fields in the schema for a 
PR Report stanza.

### description
A human-readable description of the report.

### fqcn
The fully qualified class name (fqcn) of the Report to build, which for a Juneberry 
PR Report should be equal to "**juneberry.reporting.pr.PRCurve**".

### kwargs
A dictionary containing all the arguments to pass into the `__init__` method of 
**juneberry.reporting.pr.PRCurve**.

#### output_dir
A string indicating the desired output directory for the three images produced by this 
Report type. When this field is not provided, the three images will be placed in the 
current working directory. When this field is set to a filename, the output directory 
will be set to the parent directory of that file. The filenames of the three images 
that will appear in the output directory are "pr_curve.png", "pc_curve.png", and 
"rc_curve.png".

#### iou
This float controls the iou threshold to use when generating the data for the curves. 
When not provided, the default value for this field is 0.5.

#### tp_threshold
This float controls the true positive threshold to use when generating the data for 
the curves. When not provided, the default value for this field is 0.8.

#### stats_fqcn
This string provides an opportunity to use a custom class to calculate the metrics. The 
default value for this class is "juneberry.metrics.metrics.Stats".

#### curve_sources
This dictionary contains key:value pairs that indicate which combinations of models and evaluation 
datasets should be used to add curves to each Figure. Each key should be a string corresponding to 
a model in the workspace, while each corresponding value should be a string equal to the name of a 
dataset that was used to evaluate the model. 

For example, a properly constructed 'curve_sources' field would look something like this:
```json
{
    "curve_sources": {
        "model_1": "eval_dataset_1",
        "model_1": "eval_dataset_2",
        "model_2": "eval_dataset_1"
    }
}
```

In this example, each of the three PR Figures would contain 3 curves. Two curves would come from the 
same model but different eval datasets, and the third curve would come from a different model evaluated 
with one of the previous datasets.

## Schema Details - Summary Report
This section provides more information about each of the fields in the schema for a 
Summary Report stanza.

### description
A human-readable description of the report.

### fqcn
The fully qualified class name (fqcn) of the Report to build, which for a Juneberry 
Summary Report should be equal to "**juneberry.reporting.summary.Summary**".

### kwargs
A dictionary containing all the arguments to pass into the `__init__` method of 
**juneberry.reporting.summary.Summary**.

#### md_filename
This string indicates the desired name for the output markdown file for the Summary Report. When this 
string is not provided, the output markdown file will be placed in the current working directory 
with the filename "summary.md". When a directory is provided in this field, the output markdown file 
will be placed in that directory with the filename "summary.md". When this field is set to a filename, 
then the Summary report will be saved to that file.

#### csv_filename
This string indicates that a CSV version of the Summary file is desired and what the corresponding 
filename of that CSV file should be. If this key is omitted from the kwargs, then no CSV will be 
generated. If this field is set to an empty string, then the Summary CSV will be placed in the 
current working directory with the filename "summary.csv". If this field is set to a directory, 
the output CSV file will be placed in that directory with the filename "summary.csv". When this 
field is set to a filename, then the Summary CSV will be saved to that file.

#### metrics_files
This array of strings indicates which model metrics files should contribute data to the Summary 
Report. A metrics file is an [evaluation output](eval_output_specification.md) file that does not 
contain predictions data. Each string in this array should correspond to a metrics file to pull 
summary data from. One row will be added to the Summary table for every metrics file in this array. 
When a Summary CSV has been requested, each metrics file will contribute one line to the CSV.

#### plot_files
This array of strings indicates any plot files or figures that should be included in the Summary 
Report markdown file. Any plot files included in this array will appear in the "Experiment Plots" 
section which appears below the "Experiment summary" table in the Summary markdown file. The plot 
files in this list do not contribute any information to the Summary CSV file.
