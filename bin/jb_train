#! /usr/bin/env python3

# ======================================================================================================================
#  Copyright 2021 Carnegie Mellon University.
#
#  NO WARRANTY. THIS CARNEGIE MELLON UNIVERSITY AND SOFTWARE ENGINEERING INSTITUTE MATERIAL IS FURNISHED ON AN "AS-IS"
#  BASIS. CARNEGIE MELLON UNIVERSITY MAKES NO WARRANTIES OF ANY KIND, EITHER EXPRESSED OR IMPLIED, AS TO ANY MATTER
#  INCLUDING, BUT NOT LIMITED TO, WARRANTY OF FITNESS FOR PURPOSE OR MERCHANTABILITY, EXCLUSIVITY, OR RESULTS OBTAINED
#  FROM USE OF THE MATERIAL. CARNEGIE MELLON UNIVERSITY DOES NOT MAKE ANY WARRANTY OF ANY KIND WITH RESPECT TO FREEDOM
#  FROM PATENT, TRADEMARK, OR COPYRIGHT INFRINGEMENT.
#
#  Released under a BSD (SEI)-style license, please see license.txt or contact permission@sei.cmu.edu for full terms.
#
#  [DISTRIBUTION STATEMENT A] This material has been approved for public release and unlimited distribution.
#  Please see Copyright notice for non-US Government use and distribution.
#
#  This Software includes and/or makes use of the following Third-Party Software subject to its own license:
#
#  1. PyTorch (https://github.com/pytorch/pytorch/blob/master/LICENSE) Copyright 2016 facebook, inc..
#  2. NumPY (https://github.com/numpy/numpy/blob/master/LICENSE.txt) Copyright 2020 Numpy developers.
#  3. Matplotlib (https://matplotlib.org/3.1.1/users/license.html) Copyright 2013 Matplotlib Development Team.
#  4. pillow (https://github.com/python-pillow/Pillow/blob/master/LICENSE) Copyright 2020 Alex Clark and contributors.
#  5. SKlearn (https://github.com/scikit-learn/sklearn-docbuilder/blob/master/LICENSE) Copyright 2013 scikit-learn 
#      developers.
#  6. torchsummary (https://github.com/TylerYep/torch-summary/blob/master/LICENSE) Copyright 2020 Tyler Yep.
#  7. pytest (https://docs.pytest.org/en/stable/license.html) Copyright 2020 Holger Krekel and others.
#  8. pylint (https://github.com/PyCQA/pylint/blob/main/LICENSE) Copyright 1991 Free Software Foundation, Inc..
#  9. Python (https://docs.python.org/3/license.html#psf-license) Copyright 2001 python software foundation.
#  10. doit (https://github.com/pydoit/doit/blob/master/LICENSE) Copyright 2014 Eduardo Naufel Schettino.
#  11. tensorboard (https://github.com/tensorflow/tensorboard/blob/master/LICENSE) Copyright 2017 The TensorFlow 
#                  Authors.
#  12. pandas (https://github.com/pandas-dev/pandas/blob/master/LICENSE) Copyright 2011 AQR Capital Management, LLC,
#             Lambda Foundry, Inc. and PyData Development Team.
#  13. pycocotools (https://github.com/cocodataset/cocoapi/blob/master/license.txt) Copyright 2014 Piotr Dollar and
#                  Tsung-Yi Lin.
#  14. brambox (https://gitlab.com/EAVISE/brambox/-/blob/master/LICENSE) Copyright 2017 EAVISE.
#  15. pyyaml  (https://github.com/yaml/pyyaml/blob/master/LICENSE) Copyright 2017 Ingy dÃ¶t Net ; Kirill Simonov.
#  16. natsort (https://github.com/SethMMorton/natsort/blob/master/LICENSE) Copyright 2020 Seth M. Morton.
#  17. prodict  (https://github.com/ramazanpolat/prodict/blob/master/LICENSE.txt) Copyright 2018 Ramazan Polat
#               (ramazanpolat@gmail.com).
#  18. jsonschema (https://github.com/Julian/jsonschema/blob/main/COPYING) Copyright 2013 Julian Berman.
#
#  DM21-0689
#
# ======================================================================================================================

import argparse
import logging
import sys

import juneberry.filesystem as jbfs
import juneberry.scripting as jbscripting

logger = logging.getLogger("juneberry.jb_train")


def setup_args(parser) -> None:
    """
    Adds arguments to the parser
    :param parser: The parser in which to add arguments.
    """
    parser.add_argument('modelName', help='Name of the directory in models containing the \'config.json\' in '
                                          'workspace models directory.')
    parser.add_argument('--dryrun', default=False, action='store_true',
                        help='Flag to initiate dry run mode. ')
    # parser.add_argument('--nopaging', default=False, action='store_true',
    #                     help='Set to true to disable data set paging and load all at once.')
    parser.add_argument('-n', '--num-gpus', type=int, default=None, help='The number of gpus. By default use all.'
                                                                         'Set to 0 for cpu.')


def main():
    # Setup and parse all arguments.
    parser = argparse.ArgumentParser(description="Performs the training defined in a Juneberry model "
                                                 "configuration file.")
    setup_args(parser)
    jbscripting.setup_args(parser)
    args = parser.parse_args()

    # The model manager helps us find all the files and directories
    model_name = args.modelName
    model_manager = jbfs.ModelManager(args.modelName)
    model_manager.setup()

    # Use the config file to set up the workspace, data and logging
    log_prefix = ""
    log_file = model_manager.get_training_log()
    if args.dryrun:
        log_prefix = "<<DRY_RUN>> "
        log_file = model_manager.get_training_dryrun_log_path()
    lab = jbscripting.setup_for_single_model(args, log_file=log_file, log_prefix=log_prefix, model_name=model_name,
                                             banner_msg=">>> Juneberry Trainer <<<")

    # Convert the verbose argument to the corresponding logging level.
    log_level = logging.DEBUG if args.verbose else logging.INFO

    # Kick off the logging
    logger.info(f"Beginning training with model: {model_name}")

    # Load the config files, check and aggregate configuration options
    logger.info(f"Loading model config for model {model_name} files...")
    model_config = lab.load_model_config(model_name)

    logger.info(f"Loading dataset for {model_config.training_dataset_config_path} files...")
    dataset_config = lab.load_dataset_config(model_config.training_dataset_config_path)

    max_gpus = None
    if model_config.hints is not None:
        if 'num_workers' in model_config.hints.keys():
            num_workers = model_config.hints.num_workers
            logger.warning(f"Overriding number of workers. Found {num_workers} in ModelConfig")
            lab.num_workers = num_workers
        if 'max_gpus' in model_config.hints.keys():
            max_gpus = model_config.hints.max_gpus
            lab.max_gpus = max_gpus

    # TODO: Reimplement no_paging via lab

    # This trainer will get assigned depending on what type of task is being performed.
    trainer = None

    # If the task type is classification, set up a ClassifierTrainer to do the work
    if model_config.task == "classification":
        logger.info(f"Preparing a trainer for a classification task...")
        if model_config.platform == "pytorch":
            from juneberry.pytorch.classifier_trainer import ClassifierTrainer
            trainer = ClassifierTrainer(lab, model_manager, model_config, dataset_config, log_level)
        elif model_config.platform == "pytorch_privacy":
            from juneberry.pytorch.privacy.classifier_trainer import PrivacyTrainer
            trainer = PrivacyTrainer(lab, model_manager, model_config, dataset_config, log_level)
        else:
            logger.error(f"Unrecognized platform {model_config.platform}. EXITING.")
            sys.exit(-1)

    # If the task type is object detection, set up an ObjectDetectionTrainer to do the work
    elif model_config.task == "objectDetection":
        if model_config.platform == "detectron2":
            from juneberry.detectron2.dt2_trainer import Detectron2Trainer
            trainer = Detectron2Trainer(lab, model_manager, model_config, dataset_config, log_level)
        elif model_config.platform == "mmdetection":
            from juneberry.mmdetection.mmd_trainer import MMDTrainer
            trainer = MMDTrainer(lab, model_manager, model_config, dataset_config, log_level)
        else:
            logger.error(f"Unrecognized platform {model_config.platform}. EXITING.")
            sys.exit(-1)

    if trainer is None:
        logger.error("No Trainer instantiated for configuration.  EXITING.")
        sys.exit(-1)

    if args.dryrun:
        trainer.dry_run()
    else:
        # Allocate the gpus the user asked for, getting the current number if None are required.
        trainer.num_gpus = trainer.check_gpu_availability(args.num_gpus)

        if max_gpus is not None and trainer.num_gpus > max_gpus:
            trainer.num_gpus = max_gpus
            logger.warning(f"Overriding number of gpus. Found max_gpus {max_gpus} in ModelConfig hints.")

        # No matter the number of gpus, setup the node for training
        trainer.node_setup()

        # Set the number of gpus and kick it off
        if trainer.num_gpus == 0:
            trainer.train_model()
        elif trainer.num_gpus == 1:
            # With one gpu we just run on the gpu in this process
            trainer.train_model(0)
        else:
            trainer.train_distributed(trainer.num_gpus)


if __name__ == "__main__":
    jbscripting.run_main(main, logger)
