#! /usr/bin/env python3

# ======================================================================================================================
# Juneberry - General Release
#
# Copyright 2021 Carnegie Mellon University.
#
# NO WARRANTY. THIS CARNEGIE MELLON UNIVERSITY AND SOFTWARE ENGINEERING INSTITUTE MATERIAL IS FURNISHED ON AN "AS-IS"
# BASIS. CARNEGIE MELLON UNIVERSITY MAKES NO WARRANTIES OF ANY KIND, EITHER EXPRESSED OR IMPLIED, AS TO ANY MATTER
# INCLUDING, BUT NOT LIMITED TO, WARRANTY OF FITNESS FOR PURPOSE OR MERCHANTABILITY, EXCLUSIVITY, OR RESULTS OBTAINED
# FROM USE OF THE MATERIAL. CARNEGIE MELLON UNIVERSITY DOES NOT MAKE ANY WARRANTY OF ANY KIND WITH RESPECT TO FREEDOM
# FROM PATENT, TRADEMARK, OR COPYRIGHT INFRINGEMENT.
#
# Released under a BSD (SEI)-style license, please see license.txt or contact permission@sei.cmu.edu for full terms.
#
# [DISTRIBUTION STATEMENT A] This material has been approved for public release and unlimited distribution.  Please see
# Copyright notice for non-US Government use and distribution.
#
# This Software includes and/or makes use of Third-Party Software subject to its own license.
#
# DM21-0884
#
# ======================================================================================================================

import argparse
import logging
import sys

import juneberry.filesystem as jbfs
import juneberry.platform_info
import juneberry.scripting as jbscripting
from juneberry.script_tools.training_sprout import TrainingSprout
from juneberry.training.trainer_factory import TrainerFactory

logger = logging.getLogger("juneberry.jb_train")


def setup_args(parser) -> None:
    """
    Adds arguments to the parser
    :param parser: The parser in which to add arguments.
    """
    parser.add_argument('modelName', help='Name of the directory in models containing the \'config.json\' in '
                                          'workspace models directory.')
    parser.add_argument('--dryrun', default=False, action='store_true',
                        help='Flag to initiate dry run mode. ')
    # parser.add_argument('--nopaging', default=False, action='store_true',
    #                     help='Set to true to disable data set paging and load all at once.')
    parser.add_argument('-n', '--num-gpus', type=int, default=None,
                        help='The number of GPUs. By default use all. Set to 0 for CPU.')
    parser.add_argument('--onnx', default=False, action='store_true',
                        help='When possible, save the trained model in ONNX format.')
    parser.add_argument('--skipNative', default=False, action='store_true',
                        help='Tells the trainer not to save the trained model in its native format. This argument can '
                             'potentially be ignored if no other format is chosen to take the place of the native '
                             'format. Meaning when no format is specified, native will be chosen by default.')
    parser.add_argument('--resume', default=False, action='store_true',
                        help='If the trainer supports checkpointing, then this instructs the trainer to resume training'
                             'from the last checkpoint.')


def main():
    # Setup and parse all arguments.
    parser = argparse.ArgumentParser(description="Performs the training defined in a Juneberry model "
                                                 "configuration file.")
    setup_args(parser)
    jbscripting.setup_args(parser)
    args = parser.parse_args()

    # Establish a TrainingSprout to hold the script args.
    sprout = TrainingSprout()
    sprout.grow_from_args(args)

    # The model manager helps us find all the files and directories
    # NOTE: We can use the default constructor because this model MUST be in the default (current) workspace.
    model_manager = jbfs.ModelManager(sprout.model_name)
    model_manager.setup()

    # Use the config file to set up the workspace, data and logging
    lab = jbscripting.setup_workspace_and_model(
        args,
        log_file=model_manager.get_training_log(sprout.dryrun),
        log_prefix=jbscripting.standard_line_prefix(sprout.dryrun),
        model_name=sprout.model_name,
        banner_msg=">>> Juneberry Trainer <<<")

    # Show the abbreviated platform info
    logger.info(f"Platform Info: {juneberry.platform_info.make_minimum_report()}")

    # Kick off the logging
    logger.info(f"Beginning training with model: {sprout.model_name}")

    # Load the config files, check and aggregate configuration options
    model_config = lab.load_model_config(sprout.model_name)

    # The model config may influence the lab profile, so once the model config has been
    # established it is safe to set up the lab profile.
    lab.setup_lab_profile(model_name=sprout.model_name, model_config=model_config)
    if sprout.num_gpus is not None:
        lab.profile.num_gpus = sprout.num_gpus
    logger.info(f"Using lab profile: {lab.profile}")

    # Now load the dataset
    dataset_config = lab.load_dataset_config(model_config.training_dataset_config_path)

    # TODO: Reimplement no_paging via lab profile

    # Create a TrainerFactory to generate the Trainer.
    trainer_factory = TrainerFactory(dataset_config=dataset_config, lab=lab, log_level=sprout.log_level,
                                     model_config=model_config, model_manager=model_manager)

    # Construct the trainer
    trainer = trainer_factory.get_trainer(resume=sprout.resume, native=not sprout.skip_native, onnx=sprout.onnx)

    if trainer is None:
        logger.error("No Trainer instantiated for configuration. Exiting.")
        sys.exit(-1)

    if sprout.dryrun:
        # Need to set the number of GPUs in the trainer to 0 regardless of the "true" state
        # in order to be able to successfully perform a dry run on a GPU.
        trainer.num_gpus = 0

        # TODO: Decide if the dry run should exercise GPU setup tasks. If yes, would need to
        #  remove the previous line where num_gpus was set to zero and probably set GPUs
        #  similar to how it's done below for train_model().
        trainer.dry_run()
    else:
        # Setup the node for training.
        trainer.node_setup()

        # Set the number of GPUs and kick it off
        if trainer.num_gpus == 0:
            trainer.train_model()
        elif trainer.num_gpus == 1:
            # With one GPU we just run on the GPU in this process
            trainer.train_model(0)
        else:
            trainer.train_distributed(trainer.num_gpus)

    logger.info(f"jb_train is done.")


if __name__ == "__main__":
    jbscripting.run_main(main, logger)
