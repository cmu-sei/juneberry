#! /usr/bin/env python3

# ======================================================================================================================
# Juneberry - Release 0.5
#
# Copyright 2022 Carnegie Mellon University.
#
# NO WARRANTY. THIS CARNEGIE MELLON UNIVERSITY AND SOFTWARE ENGINEERING INSTITUTE MATERIAL IS FURNISHED ON AN "AS-IS"
# BASIS. CARNEGIE MELLON UNIVERSITY MAKES NO WARRANTIES OF ANY KIND, EITHER EXPRESSED OR IMPLIED, AS TO ANY MATTER
# INCLUDING, BUT NOT LIMITED TO, WARRANTY OF FITNESS FOR PURPOSE OR MERCHANTABILITY, EXCLUSIVITY, OR RESULTS OBTAINED
# FROM USE OF THE MATERIAL. CARNEGIE MELLON UNIVERSITY DOES NOT MAKE ANY WARRANTY OF ANY KIND WITH RESPECT TO FREEDOM
# FROM PATENT, TRADEMARK, OR COPYRIGHT INFRINGEMENT.
#
# Released under a BSD (SEI)-style license, please see license.txt or contact permission@sei.cmu.edu for full terms.
#
# [DISTRIBUTION STATEMENT A] This material has been approved for public release and unlimited distribution. Please see
# Copyright notice for non-US Government use and distribution.
#
# This Software includes and/or makes use of Third-Party Software each subject to its own license.
#
# DM22-0856
#
# ======================================================================================================================

"""
This script coverts a rules file into a dodo.py file for use with pydoit.

def <task_name>():
    <docs in comment string>
    return {
        'file_dep': [  ],
        'targets': [  ],
        'actions': [  ],
        'clean': True
    }
"""

import argparse
from pathlib import Path

from juneberry.config.rule_list import RulesList
import juneberry.filesystem as jb_fs


def stringify(some_list, ):
    """
    Takes an array and turns it into an single string of quoted arguments suitable
    for printing to a file.
    :param some_list: A list of arguments.
    :return:
    """
    return ", ".join([f'"{str(x)}"' for x in some_list])


def lineify(some_list, indent):
    lines = []
    if some_list is not None:
        for idx, item in enumerate(some_list):
            if idx == len(some_list) - 1:
                lines.append(f'{indent}"{str(item)}"\n')
            else:
                lines.append(f'{indent}"{str(item)}",\n')
    return lines


def make_action(command, parallelism, concurrent=None) -> str:
    if parallelism and command[0] == "jb_train":
        # Return a string containing two quoted arguments with spaces
        joined = " ".join(command)
        if concurrent is not None:
            return f"\"jb_gpu_runner\", \"-c\", \"{concurrent}\", \"{joined}\""
        else:
            return f"\"jb_gpu_runner\", \"{joined}\""
    else:
        return stringify(command)


def make_clean_partial(out_file, rule):
    if not rule.clean_extras:
        return False

    # Make the clean_extras list.
    out_file.write(f"    clean_extras = [\n")
    out_file.writelines(lineify(rule.clean_extras, "        "))
    out_file.write(f"    ]\n")

    return True


def make_task(out_file, rule, parallelism, concurrent=None) -> None:
    out_file.write(f"\n\ndef task_{rule['id']}():\n")
    # If the rule has clean targets then we need to make a clean function
    custom_clean = make_clean_partial(out_file, rule)
    out_file.write("    return {\n")
    out_file.write(f"        'doc': \"{rule['doc']}\",\n")
    out_file.write(f"        'file_dep': [\n")
    out_file.writelines(lineify(rule["inputs"], "            "))
    out_file.write(f"        ],\n")
    out_file.write(f"        'targets': [\n")
    out_file.writelines(lineify(rule["outputs"], "            "))
    out_file.write(f"        ],\n")
    out_file.write(f"        'actions': [[{make_action(rule['command'], parallelism, concurrent)}]],\n")
    if custom_clean:
        out_file.write(f"        'clean': [clean_files, partial(custom_clean_targets, extras=clean_extras)]\n")
    else:
        out_file.write(f"        'clean': [clean_files]\n")
    out_file.write("    }\n")


# def make_group(out_file, group, tasks):
#     out_file.write(f"\ndef task_{group}():\n")
#     out_file.write("    return {\n")
#     out_file.write(f"        'actions': None,\n")
#     out_file.write(f"        'task_dep': [{stringify(tasks)}],\n")
#     out_file.write(f"        'clean': True\n")
#     out_file.write("    }\n\n")


def set_default(out_file, reader):
    defaults = []
    for workflow in reader["workflows"]:
        defaults.append(workflow["name"])

    out_file.write("\nDOIT_CONFIG = {\n")
    out_file.write(f"    'default_tasks': [{stringify(defaults)}]\n")
    out_file.write("    }\n\n")


def write_file(out_file, reader: RulesList, workflow_name, parallelism=False, concurrent=None):
    out_file.write("# ! /usr/bin/doit -f\n\n")
    out_file.write(f'# dodo.py file for the {workflow_name} workflow\n\n')

    # Some imports for the cleaning functions
    out_file.write("from functools import partial\n")
    out_file.write("from pathlib import Path\n")
    out_file.write("import shutil\n")
    out_file.write("from doit.task import clean_targets\n\n\n")

    # Emit the clean function
    out_file.write("def clean_files(task, dryrun):\n")
    out_file.write("    for target in sorted(task.targets, reverse=True):\n")
    out_file.write("        target_path = Path(target)\n")
    out_file.write("        if not target_path.exists():\n")
    out_file.write("            continue\n")
    out_file.write("        if target_path.is_file():\n")
    out_file.write("            print(f\"{task.name} - removing file '{target}'\")\n")
    out_file.write("            if not dryrun:\n")
    out_file.write("                target_path.unlink()\n")
    out_file.write("        elif target_path.is_dir():\n")
    out_file.write("            print(f\"{task.name} - removing directory {target} and all its contents\")\n")
    out_file.write("            if not dryrun:\n")
    out_file.write("                shutil.rmtree(target_path)\n\n\n")
    out_file.write("def custom_clean_targets(task, dryrun, extras):\n")
    out_file.write("    task.targets = extras\n")
    out_file.write("    clean_targets(task, dryrun)\n")

    # Emit workflows
    for workflow in reader["workflows"]:
        if workflow["name"] == workflow_name:
            for rule in workflow["rules"]:
                make_task(out_file, rule, parallelism, concurrent)
            break


def main():
    parser = argparse.ArgumentParser(
        description="Creates a python execution script for the dryrun and main workflows from the rules.json file."
    )
    parser.add_argument("experimentName", help="Name of experiment.")
    parser.add_argument("workflow", help="The name of the workflow which is being converted to a dodo file.")
    parser.add_argument("--rules", default=False, help="Path to rules.json config file.")
    parser.add_argument("--parallel", default=False, action='store_true', help="True to turn on parallelism wrapper.")
    parser.add_argument("--concurrent", action='store', default=None, type=int,
                        help="Number of concurrent jobs for parallelism.")
    args = parser.parse_args()

    # Set rules and dodo paths
    if args.rules:
        rules_path = Path(args.rules)
        dodo_path = str(rules_path.parent / f"{args.workflow}_dodo.py")
    else:
        experiment_manager = jb_fs.ExperimentManager(args.experimentName)
        rules_path = experiment_manager.get_experiment_rules()
        dodo_path = str(experiment_manager.get_experiment_dodo(args.workflow))

    # Open rules file
    rules = RulesList.load(rules_path)

    # Write main dodo file
    with open(dodo_path, "w") as main_out_file:
        write_file(main_out_file, rules, args.workflow, args.parallel, args.concurrent)


if __name__ == "__main__":
    main()
