#! /usr/bin/env python3

# ======================================================================================================================
# Juneberry - General Release
#
# Copyright 2021 Carnegie Mellon University.
#
# NO WARRANTY. THIS CARNEGIE MELLON UNIVERSITY AND SOFTWARE ENGINEERING INSTITUTE MATERIAL IS FURNISHED ON AN "AS-IS"
# BASIS. CARNEGIE MELLON UNIVERSITY MAKES NO WARRANTIES OF ANY KIND, EITHER EXPRESSED OR IMPLIED, AS TO ANY MATTER
# INCLUDING, BUT NOT LIMITED TO, WARRANTY OF FITNESS FOR PURPOSE OR MERCHANTABILITY, EXCLUSIVITY, OR RESULTS OBTAINED
# FROM USE OF THE MATERIAL. CARNEGIE MELLON UNIVERSITY DOES NOT MAKE ANY WARRANTY OF ANY KIND WITH RESPECT TO FREEDOM
# FROM PATENT, TRADEMARK, OR COPYRIGHT INFRINGEMENT.
#
# Released under a BSD (SEI)-style license, please see license.txt or contact permission@sei.cmu.edu for full terms.
#
# [DISTRIBUTION STATEMENT A] This material has been approved for public release and unlimited distribution.  Please see
# Copyright notice for non-US Government use and distribution.
#
# This Software includes and/or makes use of Third-Party Software subject to its own license.
#
# DM21-0884
#
# ======================================================================================================================

import argparse
import logging
from pathlib import Path
from typing import List

import juneberry.filesystem as jbfs
from juneberry.metrics.common_metrics import CommonMetrics, PrecisionRecallPlot, PrecisionConfidencePlot, RecallConfidencePlot
import juneberry.scripting as jbscripting


logger = logging.getLogger("juneberry.jb_plot_pr")


def setup_args(parser) -> None:
    """
    Adds arguments to the parser
    :param parser: The parser in which to add arguments.
    """
    parser.add_argument('-m', '--model', action='append', required=True,
                        help="The name of a model to generate curves for. You may provide this argument any number of "
                             "times to add multiple curves to the figures, however each model argument must be paired "
                             "with a data argument. The figure will begin to repeat line colors if more than ten "
                             "curves are added to the plot.")
    parser.add_argument('-e', '--evalData', action='append', required=True,
                        help="The name of a dataset that was used to evaluate the model. In order for a curve to be "
                             "added to the figure, a model must be paired with a dataset.")
    parser.add_argument('--iou', type=float, default=0.5,
                        help="The IoU threshold to use when determining whether to count a detection as a true "
                             "positive.")
    parser.add_argument('--outputDir', default=Path.cwd(),
                        help="Directory where figures will be saved. If this field is left unspecified, the figures "
                             "will be saved to the current working directory.")


def main():
    parser = argparse.ArgumentParser(description='This script consumes the output from jb_evaluate to create '
                                                 'three figures: a Precision-Recall curve, a Precision-Confidence '
                                                 'curve, and a Recall-Confidence curve. A curve in each figure will be '
                                                 'generated for each pair of {model, eval datasets} provided in the '
                                                 'args to this script.')
    setup_args(parser)
    jbscripting.setup_args(parser)
    args = parser.parse_args()

    # Create the output directory if it does not already exist.
    output_dir = Path(args.outputDir)
    if not output_dir.exists():
        output_dir.mkdir(parents=True)

    # Set up logging.
    jbscripting.setup_logging_for_script(args)

    logger.info(f"Starting to generate PR, PC, and RC curves...")

    metrics: List[CommonMetrics] = []

    # Create a Metrics object for each model/dataset passed in
    for idx, val in enumerate(args.model):
        model_mgr = jbfs.ModelManager(args.model[idx])
        eval_dir_mgr = model_mgr.get_eval_dir_mgr(args.evalData[idx])
        metrics.append(
            CommonMetrics.create_with_filesystem_managers(model_mgr,
                                                          eval_dir_mgr,
                                                          iou_threshold=args.iou))

    # Create empty MetricsPlots
    pr_plot = PrecisionRecallPlot()
    pc_plot = PrecisionConfidencePlot()
    rc_plot = RecallConfidencePlot()

    # Add metrics to the plots
    pr_plot.add_metrics_list(metrics)
    pc_plot.add_metrics_list(metrics)
    rc_plot.add_metrics_list(metrics)

    pr_plot.save(output_dir / "pr_curve.png")
    pc_plot.save(output_dir / "pc_curve.png")
    rc_plot.save(output_dir / "rc_curve.png")

    # Export the metrics as a CSV
    CommonMetrics.export(metrics, output_dir / "eval_metrics.csv")

    logger.info(f"jb_plot_pr is done.")


if __name__ == "__main__":
    main()
